{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T16:01:39.000608Z",
     "start_time": "2021-09-21T16:01:33.545957Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from tools import get_features\n",
    "from tools import get_results\n",
    "from tools import generate_ids_paths\n",
    "from tools import columns_to_features\n",
    "from tools import create_graphs\n",
    "from tools import create_feature_tensor\n",
    "from train import negative_sampling_3\n",
    "from train import train_model\n",
    "from train import predict_all_links\n",
    "from train import compute_confusion_matrix\n",
    "from train import metrics\n",
    "from model import CasanovaModel\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import dgl\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation and Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T13:05:21.676444Z",
     "start_time": "2021-09-21T13:05:21.673200Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_datasets = \"../datasets/opendata_small/\" # testing the method on the opendata-small configuration\n",
    "cols_to_ids, files_to_paths = generate_ids_paths(path_to_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T14:17:12.345675Z",
     "start_time": "2021-09-21T14:13:11.053184Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_features = columns_to_features(files_to_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T14:17:17.810080Z",
     "start_time": "2021-09-21T14:17:17.802508Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_tensor = create_feature_tensor(cols_features, cols_to_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group datasets per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T13:27:52.336937Z",
     "start_time": "2021-09-21T13:27:52.332962Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = list(cols_to_ids.keys())\n",
    "\n",
    "category_tables = dict()\n",
    "\n",
    "for c in cols:\n",
    "    match = re.match(r\"([a-z_]+)_([0-9]+)\", c[0], re.I)\n",
    "    \n",
    "    if match[1] in category_tables:\n",
    "        category_tables[match[1]].append(c[0])\n",
    "    else:\n",
    "        category_tables[match[1]] = [c[0]]\n",
    "\n",
    "for c,t in category_tables.items():    \n",
    "    t = list(set(t))\n",
    "    category_tables[c] = t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct relatedness graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each category, specify number of datasets to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T13:27:57.113889Z",
     "start_time": "2021-09-21T13:27:57.111414Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets_to_regard = [2,2,2,4,4] # no of samples of tables per category (e.g., for the large datasets, we would pick [10,20,30,..,100])\n",
    "i = 0\n",
    "for c,tables in category_tables.items():\n",
    "    category_tables[c] = random.sample(tables,datasets_to_regard[i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T13:27:58.075525Z",
     "start_time": "2021-09-21T13:27:58.071996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miller_bus_stops\n",
      "2\n",
      "miller_accidents\n",
      "2\n",
      "miller_train_stations\n",
      "2\n",
      "miller_applicants\n",
      "4\n",
      "miller_timetable\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for b,t in category_tables.items():\n",
    "    print(c)\n",
    "    print(len(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ground truth of matches among different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T13:28:11.730095Z",
     "start_time": "2021-09-21T13:28:11.726968Z"
    }
   },
   "outputs": [],
   "source": [
    "ground_truth_filepath = '../ground_truth/matches_opendata.txt'\n",
    "with open(ground_truth_file, 'r') as fp:\n",
    "    ground_truth = [(i.split(' ')[0], i.split(' ')[1].rstrip()) for i in fp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct relatedness graphs (configure silos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T13:28:13.550080Z",
     "start_time": "2021-09-21T13:28:13.526139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph 1 receives datasets from source miller_bus_stops\n",
      "Graph 1 receives datasets from source miller_accidents\n",
      "Graph 1 receives datasets from source miller_train_stations\n"
     ]
    }
   ],
   "source": [
    "graphs, all_columns, all_cols_ids, all_ids_cols = create_graphs(category_tables, cols_to_ids, 2, feature_tensor.tolist(),ground_truth, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get negative samples for each relatedness graph (as a negative graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T13:28:15.089193Z",
     "start_time": "2021-09-21T13:28:14.722664Z"
    }
   },
   "outputs": [],
   "source": [
    "graphs_neg = dict()\n",
    "\n",
    "for i in range(len(graphs)):\n",
    "    graphs_neg[i] = negative_sampling_3(graphs[i]) # use negative sampling strategy #3 from the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T13:28:59.957676Z",
     "start_time": "2021-09-21T13:28:51.709957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss 0.7187286615371704\n",
      "In epoch 10, loss 0.27573084831237793\n",
      "In epoch 20, loss 0.23369793593883514\n",
      "In epoch 30, loss 0.2230553776025772\n",
      "In epoch 40, loss 0.2133490890264511\n",
      "In epoch 50, loss 0.20865681767463684\n",
      "In epoch 60, loss 0.2059348076581955\n",
      "In epoch 70, loss 0.20067444443702698\n",
      "In epoch 80, loss 0.18997253477573395\n",
      "In epoch 90, loss 0.1781836897134781\n",
      "In epoch 100, loss 0.1747325211763382\n",
      "In epoch 110, loss 0.1729383021593094\n",
      "In epoch 120, loss 0.17084525525569916\n",
      "In epoch 130, loss 0.16755078732967377\n",
      "In epoch 140, loss 0.15936782956123352\n",
      "In epoch 0, loss 0.12378218024969101\n",
      "In epoch 10, loss 0.1082797646522522\n",
      "In epoch 20, loss 0.10329711437225342\n",
      "In epoch 30, loss 0.10078881680965424\n",
      "In epoch 40, loss 0.09652882814407349\n",
      "In epoch 50, loss 0.08491155505180359\n",
      "In epoch 60, loss 0.07701005786657333\n",
      "In epoch 70, loss 0.0668984204530716\n",
      "In epoch 80, loss 0.05570992827415466\n",
      "In epoch 90, loss 0.04667947441339493\n",
      "In epoch 100, loss 0.04176035150885582\n",
      "In epoch 110, loss 0.03614579141139984\n",
      "In epoch 120, loss 0.032547786831855774\n",
      "In epoch 130, loss 0.02907964028418064\n",
      "In epoch 140, loss 0.026169080287218094\n"
     ]
    }
   ],
   "source": [
    "model = train_model(graphs, graphs_neg, 150, 300, incremental=True) # train incrementally for 150 epochs per relatedness graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the model to all nodes in order to embed them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T13:30:21.593738Z",
     "start_time": "2021-09-21T13:30:21.580319Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = dict()\n",
    "\n",
    "for i in range(len(graphs)):\n",
    "\n",
    "    embeddings[i] = model.gnn(graphs[i], graphs[i].ndata['feat']).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T13:30:22.485600Z",
     "start_time": "2021-09-21T13:30:22.174897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions between graphs: 0 - 1\n",
      "Precision: 0.7518796992481203\n",
      "Recall: 0.6369426751592356\n",
      "F-score: 0.689655172413793\n"
     ]
    }
   ],
   "source": [
    "predict_all_links(all_columns, all_cols_ids, embeddings, ground_truth, model, len(graphs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get  results for a SotA matching method (EmbDI in this example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T13:30:27.828874Z",
     "start_time": "2021-09-21T13:30:27.460518Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_results_filepath = '../baseline_results/EmbDI_opendata_small_results.json'\n",
    "baseline_results = get_results(baseline_results_filepath, 'EmbDI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute effectiveness results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T13:33:20.417653Z",
     "start_time": "2021-09-21T13:33:20.376107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.03615643190948594\n",
      "Recall: 0.9\n",
      "F-score: 0.06951998108299835\n"
     ]
    }
   ],
   "source": [
    "count_tp, count_fp, _, count_fn = compute_confusion_matrix(baseline_results, ground_truth)\n",
    "metrics(count_tp, count_fp, count_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
